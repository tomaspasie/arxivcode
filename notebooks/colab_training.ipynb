{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7731a50",
   "metadata": {},
   "source": [
    "# ArXivCode: Code Encoder Training on Colab\n",
    "\n",
    "This notebook runs the contrastive learning training for the code encoder on Google Colab with free GPU access.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime → Change runtime type → GPU (T4)\n",
    "2. **Run cells in order**\n",
    "3. **Upload data** when prompted in Step 2\n",
    "4. **Monitor training** progress in Step 4\n",
    "5. **Download checkpoints** in Step 5\n",
    "\n",
    "**Estimated time**: 30-60 minutes for 3 epochs on T4 GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45502320",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - if you want to save to Drive)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccea02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository from GitHub\n",
    "# Replace with your GitHub repo URL\n",
    "!git clone https://github.com/your-username/arxivcode.git\n",
    "%cd arxivcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch transformers tqdm arxiv PyGithub python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU access\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️  No GPU detected! Enable GPU: Runtime → Change runtime type → GPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ff88a",
   "metadata": {},
   "source": [
    "## Step 2: Upload Data\n",
    "\n",
    "Upload your `parsed_pairs.json` file. You can either:\n",
    "- Upload from local machine (Option 1)\n",
    "- Load from Google Drive (Option 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload from local machine\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload parsed_pairs.json file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Create directory and move file\n",
    "!mkdir -p data/processed\n",
    "for filename in uploaded.keys():\n",
    "    !mv {filename} data/processed/parsed_pairs.json\n",
    "    print(f\"✓ Uploaded {filename} to data/processed/parsed_pairs.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Load from Google Drive (uncomment if using)\n",
    "# !mkdir -p data/processed\n",
    "# !cp /content/drive/MyDrive/arxivcode/data/processed/parsed_pairs.json data/processed/\n",
    "# print(\"✓ Loaded from Google Drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data file exists\n",
    "import os\n",
    "if os.path.exists('data/processed/parsed_pairs.json'):\n",
    "    import json\n",
    "    with open('data/processed/parsed_pairs.json') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"✓ Data loaded: {len(data)} pairs\")\n",
    "else:\n",
    "    print(\"⚠️  Error: parsed_pairs.json not found!\")\n",
    "    print(\"Please upload the file in the previous cell.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61aa550",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data (if not already done)\n",
    "\n",
    "If you haven't run the parser yet, run these cells. Otherwise skip to Step 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6adad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse paper-code pairs (only if you have paper_code_pairs.json)\n",
    "# !python src/embeddings/paper_code_parser.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup DataLoaders (creates train/val splits)\n",
    "!python src/embeddings/data_loader_setup.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea1a26",
   "metadata": {},
   "source": [
    "## Step 4: Train Model\n",
    "\n",
    "This will take 30-60 minutes on Colab T4 GPU. The training will:\n",
    "- Load CodeBERT encoders\n",
    "- Train with InfoNCE loss\n",
    "- Save best model automatically\n",
    "- Log progress to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dcb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train code encoder\n",
    "# Adjust parameters as needed:\n",
    "#   --batch_size: 8 (default) or 16 if you have memory\n",
    "#   --num_epochs: 3 (default) or more for better results\n",
    "#   --learning_rate: 2e-5 (default)\n",
    "\n",
    "!python src/embeddings/train_code_encoder.py \\\n",
    "    --json_path data/processed/parsed_pairs.json \\\n",
    "    --batch_size 8 \\\n",
    "    --num_epochs 3 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --checkpoint_dir checkpoints/code_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfb341",
   "metadata": {},
   "source": [
    "## Step 5: Monitor Training Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training history\n",
    "import json\n",
    "import os\n",
    "\n",
    "history_path = 'checkpoints/code_encoder/training_history.json'\n",
    "if os.path.exists(history_path):\n",
    "    with open(history_path) as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    print(\"Training Progress:\")\n",
    "    print(f\"  Epochs completed: {len(history['train_losses'])}\")\n",
    "    print(f\"  Train losses: {history['train_losses']}\")\n",
    "    if history['val_losses']:\n",
    "        print(f\"  Val losses: {history['val_losses']}\")\n",
    "    print(f\"  Best val loss: {history['best_val_loss']:.4f}\")\n",
    "    \n",
    "    # Simple plot\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(history['train_losses'], label='Train Loss')\n",
    "        if history['val_losses']:\n",
    "            plt.plot(history['val_losses'], label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Progress')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"(Install matplotlib for plots: !pip install matplotlib)\")\n",
    "else:\n",
    "    print(\"Training history not found yet. Training may still be running.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b8480",
   "metadata": {},
   "source": [
    "## Step 6: Save Results\n",
    "\n",
    "Download your trained model checkpoints to your local machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bd0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download checkpoints as tar.gz\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Compress checkpoints\n",
    "!tar -czf checkpoints.tar.gz checkpoints/\n",
    "\n",
    "# Download\n",
    "files.download('checkpoints.tar.gz')\n",
    "print(\"✓ Checkpoints downloaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save to Google Drive (uncomment if using)\n",
    "# !cp -r checkpoints /content/drive/MyDrive/arxivcode/\n",
    "# print(\"✓ Saved to Google Drive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b771f",
   "metadata": {},
   "source": [
    "## Step 7: Verify Checkpoints\n",
    "\n",
    "Check that your model was saved correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5de7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved checkpoints\n",
    "import os\n",
    "\n",
    "checkpoint_dir = 'checkpoints/code_encoder'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    print(\"Saved files:\")\n",
    "    for f in files:\n",
    "        filepath = os.path.join(checkpoint_dir, f)\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)  # MB\n",
    "        print(f\"  {f}: {size:.2f} MB\")\n",
    "    \n",
    "    if 'best_model.pt' in files:\n",
    "        print(\"\\n✓ Best model saved successfully!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Best model not found. Check training logs.\")\n",
    "else:\n",
    "    print(\"⚠️  Checkpoint directory not found!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
